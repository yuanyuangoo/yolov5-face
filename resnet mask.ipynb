{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NilSkBKhPthJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QmwmcXuPuLo"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WhEL6z-dBkXl",
    "outputId": "77831537-5477-42f9-d12d-76ff0ceb14c9"
   },
   "outputs": [],
   "source": [
    "train_dir=\"../test_data/ML_test_DataSet/Face_Mask_Dataset/Train/\"\n",
    "test_dir=\"../test_data/ML_test_DataSet/Face_Mask_Dataset/Test/\"\n",
    "valid_dir=\"../test_data/ML_test_DataSet/Face_Mask_Dataset/Validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnhJlc18BkXp"
   },
   "outputs": [],
   "source": [
    "classes = os.listdir(train_dir)\n",
    "classes.sort()\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AORf1yn3Pw4H",
    "outputId": "2bc3e5b6-210d-430e-a069-2a5cf6235220"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = train_dir, \n",
    "                                  transform = transforms.ToTensor())\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim = (1,2))\n",
    "    stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "    \n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gb-ZmsUOBkXv"
   },
   "outputs": [],
   "source": [
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-89cb0XBkXz"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = train_dir, \n",
    "                                  transform = train_transforms)\n",
    "\n",
    "test_data = datasets.ImageFolder(root = test_dir, \n",
    "                                 transform = test_transforms)\n",
    "\n",
    "valid_data = datasets.ImageFolder(root = valid_dir, \n",
    "                                 transform = valid_transforms)                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "-4XfHZL1xVLT",
    "outputId": "2a862f4f-25fe-4d58-8604-27ac1722d120"
   },
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlF1vQHHRESs"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjvuGeRMBkYB"
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZVxkhKxBkYD"
   },
   "outputs": [],
   "source": [
    "def plot_images(images, labels, classes, normalize = True):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        \n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        label = classes[labels[i]]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "colab_type": "code",
    "id": "TueBO2OxRQiq",
    "outputId": "0bbc6ba3-0e1b-47b3-ed1e-1b5dcc373b90"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in \n",
    "                           [train_data[i] for i in range(N_IMAGES)]])\n",
    "\n",
    "classes = test_data.classes\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zI3n_KkxBkYK"
   },
   "outputs": [],
   "source": [
    "def format_label(label):\n",
    "    label = label.split('.')[-1]\n",
    "    label = label.replace('_', ' ')\n",
    "    label = label.title()\n",
    "    label = label.replace(' ', '')\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "colab_type": "code",
    "id": "LPU5qt4hBkYO",
    "outputId": "1ac79924-9ea9-4398-da8a-f833f456f8de"
   },
   "outputs": [],
   "source": [
    "test_data.classes = [format_label(c) for c in test_data.classes]\n",
    "\n",
    "classes = test_data.classes\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvkp1FEhBkYR"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        block, n_blocks, channels = config\n",
    "        self.in_channels = channels[0]\n",
    "            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        \n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        \n",
    "        return x, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ao_fIYG2BkYU"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygLIMUX6BkYX"
   },
   "outputs": [],
   "source": [
    "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NsbYP0qrBkYZ"
   },
   "outputs": [],
   "source": [
    "resnet18_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [2,2,2,2],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet34_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [3,4,6,3],\n",
    "                               channels = [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFMwBDRVBkYc"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                               stride = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
    "                               stride = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "            \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "                \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "            \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIFUiYaCBkYg"
   },
   "outputs": [],
   "source": [
    "resnet50_config = ResNetConfig(block = Bottleneck,\n",
    "                               n_blocks = [3, 4, 6, 3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet101_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 4, 23, 3],\n",
    "                                channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet152_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 8, 36, 3],\n",
    "                                channels = [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "e0d5f6ba52604352a6484d1907385629",
      "73733f1d2af0455890e9d6f695321d89",
      "9e26aa8e760c41c4bcd81d121abb8a54",
      "d1868678a8d2487a85394a7eb6d85608",
      "dcd14c4f39ba40b1924df3921551a759",
      "2bfc54026555415b819aef84868882a0",
      "33af98c97e6141f3bfc08f9cedb4dbd0",
      "6237aa6a8e1843789e503390f5dcbd0d"
     ]
    },
    "colab_type": "code",
    "id": "qsjfsiUhRZUD",
    "outputId": "cdb95e54-4c8c-4fcf-a893-ed88a9c5650f"
   },
   "outputs": [],
   "source": [
    "pretrained_model = models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fPwZPcoZBkYt",
    "outputId": "76004c0e-53fe-442d-d504-2947b61efe62"
   },
   "outputs": [],
   "source": [
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf6xf2WVcNfY"
   },
   "outputs": [],
   "source": [
    "IN_FEATURES = pretrained_model.fc.in_features \n",
    "OUTPUT_DIM = len(test_data.classes)\n",
    "\n",
    "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ol3c207BkYz"
   },
   "outputs": [],
   "source": [
    "pretrained_model.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5rk-jdoBkY1"
   },
   "outputs": [],
   "source": [
    "model = ResNet(resnet18_config, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9lvhwjV2BkY5",
    "outputId": "e585b709-c7f9-400f-f2fe-a4c5ec3acc64"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(pretrained_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RwlzAhurBkY7",
    "outputId": "3ea4d86b-08d2-4b83-e879-b15c61649e8b"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Cuqluk1ZNOW"
   },
   "outputs": [],
   "source": [
    "START_LR = 1e-7\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JSiXTj3ZfwJ"
   },
   "outputs": [],
   "source": [
    "class LRFinder:\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        \n",
    "        torch.save(model.state_dict(), 'init_params.pt')\n",
    "\n",
    "    def range_test(self, iterator, end_lr = 10, num_iter = 100, \n",
    "                   smooth_f = 0.05, diverge_th = 5):\n",
    "        \n",
    "        lrs = []\n",
    "        losses = []\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
    "        \n",
    "        iterator = IteratorWrapper(iterator)\n",
    "        \n",
    "        for iteration in range(num_iter):\n",
    "\n",
    "            loss = self._train_batch(iterator)\n",
    "\n",
    "            #update lr\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            lrs.append(lr_scheduler.get_lr()[0])\n",
    "\n",
    "            if iteration > 0:\n",
    "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
    "                \n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if loss > diverge_th * best_loss:\n",
    "                print(\"Stopping early, the loss has diverged\")\n",
    "                break\n",
    "                       \n",
    "        #reset model to initial parameters\n",
    "        model.load_state_dict(torch.load('init_params.pt'))\n",
    "                    \n",
    "        return lrs, losses\n",
    "\n",
    "    def _train_batch(self, iterator):\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        x, y = iterator.get_batch()\n",
    "        \n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        \n",
    "        y_pred, _ = self.model(x)\n",
    "                \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "class ExponentialLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "        self.end_lr = end_lr\n",
    "        self.num_iter = num_iter\n",
    "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        curr_iter = self.last_epoch + 1\n",
    "        r = curr_iter / self.num_iter\n",
    "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
    "\n",
    "class IteratorWrapper:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self._iterator = iter(iterator)\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            inputs, labels = next(self._iterator)\n",
    "        except StopIteration:\n",
    "            self._iterator = iter(self.iterator)\n",
    "            inputs, labels, *_ = next(self._iterator)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def get_batch(self):\n",
    "        return next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fxtlrpfWZk8t",
    "outputId": "d4a73dc9-ab5a-428b-a0ed-c3d76fd4dc3e"
   },
   "outputs": [],
   "source": [
    "END_LR = 10\n",
    "NUM_ITER = 100\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "lrs, losses = lr_finder.range_test(train_iterator, END_LR, NUM_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBzT3twzZnAW"
   },
   "outputs": [],
   "source": [
    "def plot_lr_finder(lrs, losses, skip_start = 5, skip_end = 5):\n",
    "    \n",
    "    if skip_end == 0:\n",
    "        lrs = lrs[skip_start:]\n",
    "        losses = losses[skip_start:]\n",
    "    else:\n",
    "        lrs = lrs[skip_start:-skip_end]\n",
    "        losses = losses[skip_start:-skip_end]\n",
    "    \n",
    "    fig = plt.figure(figsize = (16,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(lrs, losses)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Learning rate')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.grid(True, 'both', 'x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "colab_type": "code",
    "id": "BnIQz0g4Zp5n",
    "outputId": "ff827ee8-c933-49a9-f5ac-12d6edf50c50"
   },
   "outputs": [],
   "source": [
    "plot_lr_finder(lrs, losses, skip_start = 30, skip_end = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDjS7JvNBkZR"
   },
   "outputs": [],
   "source": [
    "FOUND_LR = 2e-3\n",
    "\n",
    "params = [\n",
    "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
    "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
    "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
    "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
    "          {'params': model.fc.parameters()}\n",
    "         ]\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(params, lr = FOUND_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riS8zV2IxVMK"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = len(train_iterator)\n",
    "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "\n",
    "MAX_LRS = [p['lr'] for p in optimizer.param_groups]\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
    "                                    max_lr = MAX_LRS,\n",
    "                                    total_steps = TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_EKb_cNadbI"
   },
   "outputs": [],
   "source": [
    "def calculate_topk_accuracy(y_pred, y, k = 2):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "    return acc_1, acc_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhVOm-xcBkZa"
   },
   "source": [
    "Next up is the training function. This is similar to all the previous notebooks, but with the addition of the `scheduler` and calculating/returning top-k accuracy.\n",
    "\n",
    "The scheduler is updated by calling `scheduler.step()`. This should always be called **after** `optimizer.step()` or else the first learning rate of the scheduler will be skipped. \n",
    "\n",
    "Not all schedulers need to be called after each training batch, some are only called after each epoch. In that case, the scheduler does not need to be passed to the `train` function and can be called in the main training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr6Je0jMafsp"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, scheduler, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_k = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc_1, acc_k = calculate_topk_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_k += acc_k.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_k /= len(iterator)\n",
    "\n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85FW74KaakI_"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_k = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc_1, acc_k = calculate_topk_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            epoch_acc_k += acc_k.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_k /= len(iterator)\n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkR6LzakamOV"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "lvoyX823apEN",
    "outputId": "0cb310cb-9016-4cca-dcbb-df2f04345e99"
   },
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc_1, train_acc_k = train(model, train_iterator, optimizer, criterion, scheduler, device)\n",
    "    valid_loss, valid_acc_1, valid_acc_k = evaluate(model, valid_iterator, criterion, device)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' \\\n",
    "          f'Train Acc @k: {train_acc_k*100:6.2f}%')\n",
    "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' \\\n",
    "          f'Valid Acc @k: {valid_acc_k*100:6.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fOla2axMBkZk",
    "outputId": "a8178c45-adaa-4b00-bf59-0a1de0eb4363"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('mask_3.pt'))\n",
    "\n",
    "test_loss, test_acc_1, test_acc_k = evaluate(model, test_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc @1: {test_acc_1*100:6.2f}% | ' \\\n",
    "      f'Test Acc @k: {test_acc_k*100:6.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlCBiYxQbi4s"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim = -1)\n",
    "            top_pred = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    probs = torch.cat(probs, dim = 0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JmfK-IZ6bmlz"
   },
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scfRUtDKBkZt"
   },
   "source": [
    "... which we then use to get the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zR__HoORbpXV"
   },
   "outputs": [],
   "source": [
    "pred_labels = torch.argmax(probs, 1)\n",
    "corrects = torch.eq(labels, pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hupBoXNhbqe_"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels, classes):\n",
    "    fig = plt.figure(figsize = (20, 20))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = confusion_matrix(labels, pred_labels);\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels = classes)\n",
    "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
    "    fig.delaxes(fig.axes[1]) #delete colorbar\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xlabel('Predicted Label', fontsize = 50)\n",
    "    plt.ylabel('True Label', fontsize = 50)\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix_nomalized(labels, pred_labels, classes):\n",
    "    # fig = plt.figure(figsize = (20, 20))\n",
    "    # ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Label', fontsize = 50)\n",
    "    plt.ylabel('True Label', fontsize = 50)\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_confusion_matrix_nomalized_reversed(labels, pred_labels, classes):\n",
    "    # fig = plt.figure(figsize = (20, 20))\n",
    "    # ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = confusion_matrix(pred_labels, labels)\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('True Label', fontsize = 50)\n",
    "    plt.ylabel('Predicted Label', fontsize = 50)\n",
    "    plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "08XMzduObsMa",
    "outputId": "10e2d465-b7dd-4bb3-c3b8-73bd6453e3d5"
   },
   "outputs": [],
   "source": [
    "print(labels, pred_labels, classes)\n",
    "plot_confusion_matrix(labels,pred_labels, classes)\n",
    "plot_confusion_matrix_nomalized(labels,pred_labels, classes)\n",
    "plot_confusion_matrix_nomalized_reversed(labels, pred_labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgSkMA9dbzy8"
   },
   "outputs": [],
   "source": [
    "corrects = torch.eq(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8DbVGfYb0N_"
   },
   "outputs": [],
   "source": [
    "incorrect_examples = []\n",
    "\n",
    "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
    "    if not correct:\n",
    "        incorrect_examples.append((image, label, prob))\n",
    "\n",
    "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfbuUGh4b2M4"
   },
   "outputs": [],
   "source": [
    "def plot_most_incorrect(incorrect, classes, n_images, normalize = True):\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (25, 20))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        \n",
    "        image, true_label, probs = incorrect[i]\n",
    "        image = image.permute(1, 2, 0)\n",
    "        true_prob = probs[true_label]\n",
    "        incorrect_prob, incorrect_label = torch.max(probs, dim = 0)\n",
    "        true_class = classes[true_label]\n",
    "        incorrect_class = classes[incorrect_label]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.cpu().numpy())\n",
    "        ax.set_title(f'true label: {true_class} ({true_prob:.3f})\\n' \\\n",
    "                     f'pred label: {incorrect_class} ({incorrect_prob:.3f})')\n",
    "        ax.axis('off')\n",
    "        \n",
    "    fig.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VL56wXWtb4BT",
    "outputId": "7caa50a4-6f37-4075-b1b1-7fc2a0848fd3"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 10\n",
    "\n",
    "plot_most_incorrect(incorrect_examples, classes, N_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5UzPHw29QVi"
   },
   "outputs": [],
   "source": [
    "def get_representations(model, iterator):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    outputs = []\n",
    "    intermediates = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            outputs.append(y_pred.cpu())\n",
    "            labels.append(y)\n",
    "        \n",
    "    outputs = torch.cat(outputs, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "\n",
    "    return outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYvJXnuu9by8"
   },
   "outputs": [],
   "source": [
    "outputs, labels = get_representations(model, train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6C0vTaVm9dha"
   },
   "outputs": [],
   "source": [
    "def get_pca(data, n_components = 2):\n",
    "    pca = decomposition.PCA()\n",
    "    pca.n_components = n_components\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHQfixt09fMO"
   },
   "outputs": [],
   "source": [
    "def plot_representations(data, labels, classes, n_images = None):\n",
    "            \n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "        labels = labels[:n_images]\n",
    "                \n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(data[:, 0], data[:, 1], c = labels, cmap = 'viridis')\n",
    "    handles, _ = scatter.legend_elements(num = None)\n",
    "    legend = plt.legend(handles = handles, labels = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "colab_type": "code",
    "id": "TpZQLiLZ9hdh",
    "outputId": "ff8114df-56ea-4d08-c628-d00ced87382c"
   },
   "outputs": [],
   "source": [
    "output_pca_data = get_pca(outputs)\n",
    "plot_representations(output_pca_data, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pz6yxrS29i9D"
   },
   "outputs": [],
   "source": [
    "def get_tsne(data, n_components = 2, n_images = None):\n",
    "    \n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "        \n",
    "    tsne = manifold.TSNE(n_components = n_components, random_state = 0)\n",
    "    tsne_data = tsne.fit_transform(data)\n",
    "    return tsne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "colab_type": "code",
    "id": "fe8v2Z2v9koj",
    "outputId": "41f8e18d-611b-43e9-90b8-8aec133a659c"
   },
   "outputs": [],
   "source": [
    "output_tsne_data = get_tsne(outputs)\n",
    "plot_representations(output_tsne_data, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDqM5kXc9mU7"
   },
   "outputs": [],
   "source": [
    "def plot_filtered_images(images, filters, n_filters = None, normalize = True):\n",
    "\n",
    "    images = torch.cat([i.unsqueeze(0) for i in images], dim = 0).cpu()\n",
    "    filters = filters.cpu()\n",
    "\n",
    "    if n_filters is not None:\n",
    "        filters = filters[:n_filters]\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "    n_filters = filters.shape[0]\n",
    "\n",
    "    filtered_images = F.conv2d(images, filters)\n",
    "\n",
    "    fig = plt.figure(figsize = (30, 30))\n",
    "\n",
    "    for i in range(n_images):\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters))\n",
    "        ax.imshow(image.permute(1,2,0).numpy())\n",
    "        ax.set_title('Original')\n",
    "        ax.axis('off')\n",
    "\n",
    "        for j in range(n_filters):\n",
    "            image = filtered_images[i][j]\n",
    "\n",
    "            if normalize:\n",
    "                image = normalize_image(image)\n",
    "\n",
    "            ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters)+j+1)\n",
    "            ax.imshow(image.numpy(), cmap = 'bone')\n",
    "            ax.set_title(f'Filter {j+1}')\n",
    "            ax.axis('off');\n",
    "\n",
    "    fig.subplots_adjust(hspace = -0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 965
    },
    "colab_type": "code",
    "id": "Gknz19kp9onk",
    "outputId": "5ae3049a-2ce5-4f84-d1f3-ddd96931deb2"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 5\n",
    "N_FILTERS = 7\n",
    "\n",
    "images = [image for image, label in [train_data[i] for i in range(N_IMAGES)]]\n",
    "filters = model.conv1.weight.data\n",
    "\n",
    "plot_filtered_images(images, filters, N_FILTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOGoonSkxVNk"
   },
   "outputs": [],
   "source": [
    "def plot_filters(filters, normalize = True):\n",
    "\n",
    "    filters = filters.cpu()\n",
    "\n",
    "    n_filters = filters.shape[0]\n",
    "\n",
    "    rows = int(np.sqrt(n_filters))\n",
    "    cols = int(np.sqrt(n_filters))\n",
    "\n",
    "    fig = plt.figure(figsize = (30, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        image = filters[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "        \n",
    "    fig.subplots_adjust(wspace = -0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "id": "vqru5kYNxVNm",
    "outputId": "cb0d8899-2995-4b54-9eaf-65926c5d5d0a"
   },
   "outputs": [],
   "source": [
    "plot_filters(filters)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "5 - ResNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "1b8359f1dd318c6a8111fb47da3c716d5c1b0b83da1d250fef763b9d4559f91f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('th')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2bfc54026555415b819aef84868882a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33af98c97e6141f3bfc08f9cedb4dbd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6237aa6a8e1843789e503390f5dcbd0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73733f1d2af0455890e9d6f695321d89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e26aa8e760c41c4bcd81d121abb8a54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bfc54026555415b819aef84868882a0",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dcd14c4f39ba40b1924df3921551a759",
      "value": 102502400
     }
    },
    "d1868678a8d2487a85394a7eb6d85608": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6237aa6a8e1843789e503390f5dcbd0d",
      "placeholder": "​",
      "style": "IPY_MODEL_33af98c97e6141f3bfc08f9cedb4dbd0",
      "value": " 97.8M/97.8M [00:00&lt;00:00, 114MB/s]"
     }
    },
    "dcd14c4f39ba40b1924df3921551a759": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e0d5f6ba52604352a6484d1907385629": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e26aa8e760c41c4bcd81d121abb8a54",
       "IPY_MODEL_d1868678a8d2487a85394a7eb6d85608"
      ],
      "layout": "IPY_MODEL_73733f1d2af0455890e9d6f695321d89"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
